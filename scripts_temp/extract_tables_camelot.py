"""
extract_tables_camelot.py - Camelot ê¸°ë°˜ Part 9 í…Œì´ë¸” ì¶”ì¶œ
í…ŒìŠ¤íŠ¸ ê²°ê³¼ Camelotì´ 78.8%ë¡œ ìµœê³  ì„±ëŠ¥

íŠ¹ì§•:
1. lattice (ì„  ê¸°ë°˜) ìš°ì„ , ì‹¤íŒ¨ì‹œ stream (ê³µë°± ê¸°ë°˜) ì‹œë„
2. filldownìœ¼ë¡œ ë³‘í•© ì…€ ì²˜ë¦¬
3. ë‹¤ì¤‘ í—¤ë” í–‰ ìë™ ê°ì§€
4. ê²€ì¦ ë° í’ˆì§ˆ ë¦¬í¬íŠ¸
"""

import sys
import os
import json
import re
from copy import deepcopy
from datetime import datetime

sys.stdout.reconfigure(encoding='utf-8')

try:
    import camelot
except ImportError:
    print("âŒ Camelotì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   pip install camelot-py[cv]")
    sys.exit(1)

PDF_PATH = '../source/2024 Building Code Compendium/301880.pdf'
OUTPUT_DIR = '../codevault/public/data'

# Part 9 í˜ì´ì§€ ë²”ìœ„
START_PAGE = 715
END_PAGE = 1050


def get_pdf_path():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.normpath(os.path.join(script_dir, PDF_PATH))


def get_output_path():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.normpath(os.path.join(script_dir, OUTPUT_DIR))


def filldown_cells(data):
    """ë³‘í•© ì…€ ì²˜ë¦¬: None/ë¹ˆ ê°’ì„ ìœ„ì˜ ê°’ìœ¼ë¡œ ì±„ì›€"""
    if not data:
        return data

    result = deepcopy(data)

    for col in range(len(result[0]) if result else 0):
        last_value = None
        for row in range(len(result)):
            cell = result[row][col]
            if cell is None or (isinstance(cell, str) and cell.strip() == ''):
                result[row][col] = last_value
            else:
                last_value = str(cell).strip()
                result[row][col] = last_value

    return result


def clean_cell(cell):
    """ì…€ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
    if cell is None:
        return None

    text = str(cell).strip()
    # ì—¬ëŸ¬ ì¤„ ë°”ê¿ˆ â†’ ê³µë°±
    text = re.sub(r'\n+', ' ', text)
    # ì—°ì† ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)

    return text.strip() if text.strip() else None


def clean_table(data):
    """í…Œì´ë¸” ë°ì´í„° ì •ë¦¬"""
    if not data:
        return []

    cleaned = []
    for row in data:
        cleaned_row = [clean_cell(cell) for cell in row]
        # ëª¨ë“  ì…€ì´ ë¹„ì–´ìˆìœ¼ë©´ ì œì™¸
        if any(cell is not None for cell in cleaned_row):
            cleaned.append(cleaned_row)

    return cleaned


def detect_header_rows(table_data):
    """í—¤ë” í–‰ ìˆ˜ ìë™ ê°ì§€"""
    if not table_data or len(table_data) < 2:
        return 1

    header_rows = 1

    # ì²˜ìŒ 4í–‰ ë¶„ì„
    for i, row in enumerate(table_data[:4]):
        # ìˆ«ìê°€ ë§ìœ¼ë©´ ë°ì´í„° í–‰ìœ¼ë¡œ íŒë‹¨
        numeric_count = sum(1 for cell in row if cell and re.match(r'^[\d.,\-\s]+$', str(cell)))

        if numeric_count > len(row) / 2:
            break
        header_rows = i + 1

    return min(header_rows, 3)  # ìµœëŒ€ 3í–‰


def find_table_id(page_text):
    """í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ í…Œì´ë¸” ID ì°¾ê¸°"""
    pattern = r'Table\s+(\d+\.\d+\.\d+\.\d+(?:\.-[A-Z])?(?:-[A-Z])?)'
    matches = re.findall(pattern, page_text, re.IGNORECASE)

    # ì¤‘ë³µ ì œê±°í•˜ê³  ì²« ë²ˆì§¸ ë°˜í™˜
    seen = set()
    unique = []
    for m in matches:
        if m not in seen:
            seen.add(m)
            unique.append(m)

    return unique


def extract_table_from_page(pdf_path, page_num):
    """ë‹¨ì¼ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ (Camelot)"""
    tables_extracted = []

    # 1. Lattice (ì„  ê¸°ë°˜) ë¨¼ì € ì‹œë„
    try:
        tables = camelot.read_pdf(
            pdf_path,
            pages=str(page_num),
            flavor='lattice',
            line_scale=40,
            process_background=True
        )

        for i, table in enumerate(tables):
            df = table.df
            data = df.values.tolist()

            if data and len(data) > 1:
                # ì •ë¦¬ ë° filldown
                cleaned = clean_table(data)
                filled = filldown_cells(cleaned)

                if filled:
                    tables_extracted.append({
                        'source': 'lattice',
                        'accuracy': table.accuracy if hasattr(table, 'accuracy') else 0,
                        'data': filled
                    })

    except Exception as e:
        pass  # lattice ì‹¤íŒ¨ì‹œ stream ì‹œë„

    # 2. Stream (ê³µë°± ê¸°ë°˜) - lattice ê²°ê³¼ê°€ ì—†ê±°ë‚˜ í’ˆì§ˆ ë‚®ì„ ë•Œ
    if not tables_extracted:
        try:
            tables = camelot.read_pdf(
                pdf_path,
                pages=str(page_num),
                flavor='stream',
                edge_tol=50,
                row_tol=15
            )

            for i, table in enumerate(tables):
                df = table.df
                data = df.values.tolist()

                if data and len(data) > 1:
                    cleaned = clean_table(data)
                    filled = filldown_cells(cleaned)

                    if filled:
                        tables_extracted.append({
                            'source': 'stream',
                            'accuracy': table.accuracy if hasattr(table, 'accuracy') else 0,
                            'data': filled
                        })

        except Exception as e:
            pass

    return tables_extracted


def extract_all_tables():
    """Part 9 ì „ì²´ í…Œì´ë¸” ì¶”ì¶œ"""
    pdf_path = get_pdf_path()
    output_path = get_output_path()

    print("=" * 70)
    print("ğŸš€ Part 9 í…Œì´ë¸” ì¶”ì¶œ (Camelot ê¸°ë°˜)")
    print(f"   PDF: {pdf_path}")
    print(f"   ë²”ìœ„: p.{START_PAGE} - p.{END_PAGE}")
    print("=" * 70)

    all_tables = []
    pages_with_tables = 0
    total_tables = 0

    # í˜ì´ì§€ë³„ ì¶”ì¶œ
    for page_num in range(START_PAGE, END_PAGE + 1):
        tables = extract_table_from_page(pdf_path, page_num)

        if tables:
            pages_with_tables += 1

            for idx, table_info in enumerate(tables):
                data = table_info['data']
                header_rows = detect_header_rows(data)

                # í…Œì´ë¸” ì •ë³´ êµ¬ì„±
                table_entry = {
                    'page': page_num,
                    'index': idx,
                    'source': table_info['source'],
                    'accuracy': table_info.get('accuracy', 0),
                    'rows': len(data),
                    'cols': len(data[0]) if data else 0,
                    'header_rows': header_rows,
                    'headers': data[:header_rows] if data else [],
                    'data': data[header_rows:] if len(data) > header_rows else [],
                    'raw_data': data
                }

                all_tables.append(table_entry)
                total_tables += 1

            # ì§„í–‰ ìƒí™© ì¶œë ¥ (10í˜ì´ì§€ë§ˆë‹¤)
            if (page_num - START_PAGE) % 50 == 0:
                print(f"   ì§„í–‰: p.{page_num} / {total_tables} í…Œì´ë¸”...")

    print(f"\nğŸ“Š ì¶”ì¶œ ì™„ë£Œ:")
    print(f"   ì´ í˜ì´ì§€: {END_PAGE - START_PAGE + 1}")
    print(f"   í…Œì´ë¸” í¬í•¨ í˜ì´ì§€: {pages_with_tables}")
    print(f"   ì´ í…Œì´ë¸” ìˆ˜: {total_tables}")

    # JSON ì €ì¥
    os.makedirs(output_path, exist_ok=True)
    output_file = os.path.join(output_path, 'part9_tables_camelot.json')

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_tables, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ì €ì¥ë¨: {output_file}")

    # í’ˆì§ˆ ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“‹ í’ˆì§ˆ ìš”ì•½")
    print("=" * 70)

    lattice_count = sum(1 for t in all_tables if t['source'] == 'lattice')
    stream_count = sum(1 for t in all_tables if t['source'] == 'stream')

    print(f"   Lattice ì¶”ì¶œ: {lattice_count}ê°œ")
    print(f"   Stream ì¶”ì¶œ: {stream_count}ê°œ")

    # ìƒ˜í”Œ ì¶œë ¥
    print("\nìƒ˜í”Œ í…Œì´ë¸” (ì²˜ìŒ 3ê°œ):")
    for t in all_tables[:3]:
        print(f"\n  ğŸ“Š í˜ì´ì§€ {t['page']} ({t['source']}, {t['rows']}x{t['cols']})")
        print(f"     í—¤ë”: {t['headers'][0][:3] if t['headers'] else 'N/A'}...")
        if t['data']:
            print(f"     ì²« í–‰: {t['data'][0][:3]}...")

    return all_tables


def validate_extraction(tables):
    """ì¶”ì¶œ ê²°ê³¼ ê²€ì¦"""
    print("\n" + "=" * 70)
    print("âœ… ê²€ì¦")
    print("=" * 70)

    issues = []

    for t in tables:
        # 1. ë¹ˆ í…Œì´ë¸”
        if not t['raw_data']:
            issues.append(f"p.{t['page']}: ë¹ˆ í…Œì´ë¸”")

        # 2. ì—´ ìˆ˜ ë¶ˆì¼ì¹˜
        col_counts = [len(row) for row in t['raw_data']]
        if len(set(col_counts)) > 1:
            issues.append(f"p.{t['page']}: ì—´ ìˆ˜ ë¶ˆì¼ì¹˜ {set(col_counts)}")

        # 3. ë„ˆë¬´ ë§ì€ ë¹ˆ ì…€
        total_cells = sum(len(row) for row in t['raw_data'])
        null_cells = sum(1 for row in t['raw_data'] for c in row if c is None or c == '')
        if total_cells > 0 and null_cells / total_cells > 0.5:
            issues.append(f"p.{t['page']}: ë¹ˆ ì…€ {null_cells/total_cells*100:.0f}%")

    if issues:
        print(f"   âš ï¸ ë°œê²¬ëœ ë¬¸ì œ: {len(issues)}ê°œ")
        for issue in issues[:10]:
            print(f"      - {issue}")
    else:
        print("   âœ… ë¬¸ì œ ì—†ìŒ")

    return len(issues) == 0


if __name__ == "__main__":
    tables = extract_all_tables()
    validate_extraction(tables)
    print("\nğŸ‰ ì™„ë£Œ!")
