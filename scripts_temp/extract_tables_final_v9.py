"""
extract_tables_final_v9.py - ìµœì í™”ëœ í…Œì´ë¸” ì¶”ì¶œ
- ë¹ ë¥¸ ì†ë„: PyMuPDFë¡œ í…Œì´ë¸” ê°ì§€, Camelotìœ¼ë¡œ ì •ë°€ ì¶”ì¶œ
- í•˜ì´ë¸Œë¦¬ë“œ: ê°ì§€ ì‹¤íŒ¨ì‹œ stream ëª¨ë“œë¡œ í´ë°±
- ê²€ì¦ í¬í•¨
"""

import sys
import os
import json
import re
from copy import deepcopy
from datetime import datetime

sys.stdout.reconfigure(encoding='utf-8')

import fitz  # PyMuPDF for fast detection
import pdfplumber  # backup option

try:
    import camelot
    HAS_CAMELOT = True
except ImportError:
    HAS_CAMELOT = False
    print("âš ï¸ Camelot ì—†ìŒ - pdfplumber ì‚¬ìš©")

PDF_PATH = '../source/2024 Building Code Compendium/301880.pdf'
OUTPUT_DIR = '../codevault/public/data'

# Part 9 ë²”ìœ„
START_PAGE = 715
END_PAGE = 1050


def get_paths():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    pdf_path = os.path.normpath(os.path.join(script_dir, PDF_PATH))
    output_path = os.path.normpath(os.path.join(script_dir, OUTPUT_DIR))
    return pdf_path, output_path


def filldown_cells(data):
    """ë³‘í•© ì…€ ì²˜ë¦¬"""
    if not data:
        return data
    result = deepcopy(data)
    for col in range(len(result[0]) if result else 0):
        last_value = None
        for row in range(len(result)):
            cell = result[row][col]
            if cell is None or (isinstance(cell, str) and cell.strip() == ''):
                result[row][col] = last_value
            else:
                last_value = str(cell).strip()
                result[row][col] = last_value
    return result


def clean_cell(cell):
    if cell is None:
        return None
    text = str(cell).strip()
    text = re.sub(r'\n+', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip() if text.strip() else None


def clean_table(data):
    if not data:
        return []
    cleaned = []
    for row in data:
        cleaned_row = [clean_cell(cell) for cell in row]
        if any(cell is not None for cell in cleaned_row):
            cleaned.append(cleaned_row)
    return cleaned


def detect_tables_pymupdf(pdf_path):
    """PyMuPDFë¡œ ë¹ ë¥´ê²Œ í…Œì´ë¸” ìœ„ì¹˜ ê°ì§€"""
    print("1ë‹¨ê³„: PyMuPDFë¡œ í…Œì´ë¸” ìœ„ì¹˜ ìŠ¤ìº”...")

    doc = fitz.open(pdf_path)
    table_pages = []

    for page_num in range(START_PAGE - 1, min(END_PAGE, len(doc))):
        page = doc[page_num]
        tabs = page.find_tables()

        if tabs.tables:
            table_info = []
            for tab in tabs.tables:
                table_info.append({
                    'bbox': tab.bbox,
                    'rows': tab.row_count,
                    'cols': tab.col_count
                })
            table_pages.append({
                'page': page_num + 1,
                'tables': table_info
            })

    doc.close()
    print(f"   â†’ {len(table_pages)} í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ë°œê²¬")
    return table_pages


def extract_with_pdfplumber(pdf_path, page_num):
    """pdfplumberë¡œ í…Œì´ë¸” ì¶”ì¶œ (í´ë°±)"""
    with pdfplumber.open(pdf_path) as pdf:
        if page_num - 1 >= len(pdf.pages):
            return []

        page = pdf.pages[page_num - 1]
        tables = page.extract_tables()

        results = []
        for table in tables:
            if table and len(table) > 1:
                cleaned = clean_table(table)
                filled = filldown_cells(cleaned)
                if filled:
                    results.append({
                        'source': 'pdfplumber',
                        'data': filled
                    })
        return results


def extract_with_camelot(pdf_path, page_num):
    """Camelotìœ¼ë¡œ í…Œì´ë¸” ì¶”ì¶œ"""
    if not HAS_CAMELOT:
        return extract_with_pdfplumber(pdf_path, page_num)

    results = []

    # Lattice ë¨¼ì €
    try:
        tables = camelot.read_pdf(pdf_path, pages=str(page_num), flavor='lattice')
        for table in tables:
            df = table.df
            data = df.values.tolist()
            if data and len(data) > 1:
                cleaned = clean_table(data)
                filled = filldown_cells(cleaned)
                if filled:
                    results.append({
                        'source': 'camelot-lattice',
                        'accuracy': table.accuracy if hasattr(table, 'accuracy') else 0,
                        'data': filled
                    })
    except:
        pass

    # Lattice ì‹¤íŒ¨ì‹œ Stream
    if not results:
        try:
            tables = camelot.read_pdf(pdf_path, pages=str(page_num), flavor='stream')
            for table in tables:
                df = table.df
                data = df.values.tolist()
                if data and len(data) > 1:
                    cleaned = clean_table(data)
                    filled = filldown_cells(cleaned)
                    if filled:
                        results.append({
                            'source': 'camelot-stream',
                            'accuracy': table.accuracy if hasattr(table, 'accuracy') else 0,
                            'data': filled
                        })
        except:
            pass

    # Camelot ì‹¤íŒ¨ì‹œ pdfplumber
    if not results:
        results = extract_with_pdfplumber(pdf_path, page_num)

    return results


def find_table_id_on_page(pdf_path, page_num):
    """í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ID ì°¾ê¸°"""
    doc = fitz.open(pdf_path)
    page = doc[page_num - 1]
    text = page.get_text()
    doc.close()

    pattern = r'Table\s+(\d+\.\d+\.\d+\.\d+(?:-[A-Z])?)'
    matches = re.findall(pattern, text, re.IGNORECASE)

    return list(dict.fromkeys(matches))  # ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€


def extract_all_tables():
    """ì „ì²´ ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤"""
    pdf_path, output_path = get_paths()

    print("=" * 70)
    print("ğŸš€ Part 9 í…Œì´ë¸” ì¶”ì¶œ v9 (í•˜ì´ë¸Œë¦¬ë“œ)")
    print(f"   PDF: {pdf_path}")
    print(f"   ë²”ìœ„: p.{START_PAGE} - p.{END_PAGE}")
    print("=" * 70)

    # 1ë‹¨ê³„: ë¹ ë¥¸ ìŠ¤ìº”
    table_pages = detect_tables_pymupdf(pdf_path)

    if not table_pages:
        print("âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    # 2ë‹¨ê³„: ì •ë°€ ì¶”ì¶œ
    print(f"\n2ë‹¨ê³„: ì •ë°€ ì¶”ì¶œ ({len(table_pages)} í˜ì´ì§€)...")

    all_tables = []
    source_counts = {'camelot-lattice': 0, 'camelot-stream': 0, 'pdfplumber': 0}

    for i, page_info in enumerate(table_pages):
        page_num = page_info['page']

        # í…Œì´ë¸” ID ì°¾ê¸°
        table_ids = find_table_id_on_page(pdf_path, page_num)

        # ì¶”ì¶œ
        extracted = extract_with_camelot(pdf_path, page_num)

        for idx, table_data in enumerate(extracted):
            data = table_data['data']
            source = table_data.get('source', 'unknown')
            source_counts[source] = source_counts.get(source, 0) + 1

            # í…Œì´ë¸” ID ë§¤ì¹­ (ì¶”ì¶œ ìˆœì„œëŒ€ë¡œ)
            table_id = table_ids[idx] if idx < len(table_ids) else None

            table_entry = {
                'page': page_num,
                'index': idx,
                'table_id': table_id,
                'source': source,
                'accuracy': table_data.get('accuracy', 0),
                'rows': len(data),
                'cols': len(data[0]) if data else 0,
                'headers': data[0] if data else [],
                'data': data[1:] if len(data) > 1 else [],
                'raw_data': data
            }
            all_tables.append(table_entry)

        # ì§„í–‰ ìƒí™© (10ê°œë§ˆë‹¤)
        if (i + 1) % 10 == 0:
            print(f"   ì§„í–‰: {i+1}/{len(table_pages)} í˜ì´ì§€...")

    print(f"\nğŸ“Š ì¶”ì¶œ ì™„ë£Œ:")
    print(f"   ì´ í…Œì´ë¸”: {len(all_tables)}ê°œ")
    for source, count in source_counts.items():
        if count > 0:
            print(f"   - {source}: {count}ê°œ")

    # ì €ì¥
    os.makedirs(output_path, exist_ok=True)
    output_file = os.path.join(output_path, 'part9_tables_v9.json')

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_tables, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ì €ì¥ë¨: {output_file}")

    # ê²€ì¦
    validate_and_report(all_tables)

    return all_tables


def validate_and_report(tables):
    """ê²€ì¦ ë° ë¦¬í¬íŠ¸"""
    print("\n" + "=" * 70)
    print("âœ… ê²€ì¦ ë¦¬í¬íŠ¸")
    print("=" * 70)

    # í†µê³„
    total_rows = sum(t['rows'] for t in tables)
    with_id = sum(1 for t in tables if t.get('table_id'))

    print(f"   í…Œì´ë¸” ìˆ˜: {len(tables)}")
    print(f"   ì´ í–‰ ìˆ˜: {total_rows}")
    print(f"   ID ìˆëŠ” í…Œì´ë¸”: {with_id}/{len(tables)}")

    # ë¬¸ì œ í…Œì´ë¸”
    issues = []
    for t in tables:
        null_count = sum(1 for row in t['raw_data'] for c in row if c is None or c == '')
        total = t['rows'] * t['cols']
        if total > 0 and null_count / total > 0.3:
            issues.append(f"p.{t['page']} ({t.get('table_id', 'N/A')}): NULL {null_count/total*100:.0f}%")

    if issues:
        print(f"\n   âš ï¸ ì£¼ì˜ í•„ìš” ({len(issues)}ê°œ):")
        for issue in issues[:5]:
            print(f"      - {issue}")
    else:
        print("\n   âœ… ëª¨ë“  í…Œì´ë¸” í’ˆì§ˆ ì–‘í˜¸")

    # ìƒ˜í”Œ
    print("\nğŸ“‹ ìƒ˜í”Œ í…Œì´ë¸” (ì²˜ìŒ 3ê°œ):")
    for t in tables[:3]:
        print(f"\n  ğŸ“Š {t.get('table_id', 'Unknown')} (p.{t['page']}, {t['source']})")
        print(f"     í¬ê¸°: {t['rows']}x{t['cols']}")
        if t['headers']:
            print(f"     í—¤ë”: {t['headers'][:3]}...")


if __name__ == "__main__":
    tables = extract_all_tables()
    print("\nğŸ‰ ì™„ë£Œ!")
