#!/usr/bin/env python3
"""
Part JSON ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ìƒˆë¡œìš´ Partë¥¼ íŒŒì‹±í•œ í›„ í’ˆì§ˆ ê²€ì¦ì„ ìœ„í•´ ì‚¬ìš©

ì‚¬ìš©ë²•:
    python scripts/validate_part.py codevault/public/data/part10.json
    python scripts/validate_part.py obc.db --db --part 10
"""

import json
import re
import sys
import sqlite3
import io

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
from pathlib import Path
from typing import List, Dict, Tuple
from collections import defaultdict


class ParsingValidator:
    def __init__(self):
        self.errors: List[Tuple[str, str, str]] = []  # (level, node_id, message)
        self.warnings: List[Tuple[str, str, str]] = []
        self.stats = defaultdict(int)

    def validate_json(self, json_path: str) -> bool:
        """JSON íŒŒì¼ ê²€ì¦"""
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"\n{'='*60}")
        print(f"Validating: {json_path}")
        print(f"{'='*60}")

        if isinstance(data, list):
            for node in data:
                self._validate_node_recursive(node)
        elif isinstance(data, dict):
            self._validate_node_recursive(data)

        return self._report()

    def validate_db(self, db_path: str, part: str) -> bool:
        """SQLite DBì—ì„œ íŠ¹ì • Part ê²€ì¦"""
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        print(f"\n{'='*60}")
        print(f"Validating Part {part} from: {db_path}")
        print(f"{'='*60}")

        # Part ë²ˆí˜¸ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ë…¸ë“œ ê°€ì ¸ì˜¤ê¸°
        cursor.execute(
            "SELECT id, title, content FROM nodes WHERE id LIKE ?",
            (f"{part}.%",)
        )

        for row in cursor.fetchall():
            node_id, title, content = row
            self._validate_node({
                'id': node_id,
                'title': title or '',
                'content': content or ''
            })

        conn.close()
        return self._report()

    def _validate_node_recursive(self, node: Dict):
        """ë…¸ë“œì™€ í•˜ìœ„ ë…¸ë“œë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ ê²€ì¦"""
        self._validate_node(node)

        # í•˜ìœ„ ë…¸ë“œë“¤ ì¬ê·€ íƒìƒ‰
        for key in ['sections', 'subsections', 'articles']:
            if key in node and isinstance(node[key], list):
                for child in node[key]:
                    self._validate_node_recursive(child)

    def _validate_node(self, node: Dict):
        """ë‹¨ì¼ ë…¸ë“œ ê²€ì¦"""
        node_id = node.get('id', 'unknown')
        content = node.get('content', '')
        title = node.get('title', '')

        self.stats['total_nodes'] += 1

        if not content:
            self.warnings.append(('WARN', node_id, 'Empty content'))
            return

        self.stats['total_content_length'] += len(content)

        # 1. ë§ˆí¬ë‹¤ìš´ í—¤ë”© ì”ë¥˜ ê²€ì‚¬
        if re.search(r'^#{2,4}\s+', content, re.MULTILINE):
            self.errors.append(('ERROR', node_id, 'RAW_MARKDOWN_HEADING: ###/##/#### ë§ˆí¬ë‹¤ìš´ í—¤ë”© ì”ë¥˜'))

        # 2. ë³¼ë“œ ë§ˆí¬ë‹¤ìš´ ì”ë¥˜ ê²€ì‚¬
        if re.search(r'^\*\*[A-Z].*\*\*$', content, re.MULTILINE):
            self.errors.append(('ERROR', node_id, 'RAW_BOLD: **ë³¼ë“œ** ë§ˆí¬ë‹¤ìš´ ì”ë¥˜'))

        # 3. ì´íƒ¤ë¦­ ë§ˆí¬ë‹¤ìš´ ì”ë¥˜ ê²€ì‚¬ (ë³¼ë“œ ì œì™¸)
        if re.search(r'^\*[A-Z].*[^*]\*$', content, re.MULTILINE):
            if not re.search(r'^\*\*', content, re.MULTILINE):
                self.warnings.append(('WARN', node_id, 'RAW_ITALIC: *ì´íƒ¤ë¦­* ë§ˆí¬ë‹¤ìš´ ì”ë¥˜ ê°€ëŠ¥ì„±'))

        # 4. Flat table íŒ¨í„´ ê²€ì‚¬ (C.A. Number)
        if re.search(r'C\.A\.\s*Number.*Division B.*Compliance', content, re.IGNORECASE):
            if not re.search(r'<table[\s>]', content, re.IGNORECASE):
                self.errors.append(('ERROR', node_id, 'FLAT_TABLE: C.A. Number í…Œì´ë¸”ì´ <table>ë¡œ ë³€í™˜ ì•ˆë¨'))

        # 5. H.I. í…Œì´ë¸” íŒ¨í„´ ê²€ì‚¬
        if re.search(r'(?:Small|Medium|Large)\s+(?:Small|Medium|Large)\s+\d', content):
            if not re.search(r'<table[\s>]', content, re.IGNORECASE):
                self.warnings.append(('WARN', node_id, 'POSSIBLE_FLAT_HI_TABLE: H.I. í…Œì´ë¸” flat text ê°€ëŠ¥ì„±'))

        # 6. í…Œì´ë¸” í—¤ë”© vs <table> íƒœê·¸ ë¶ˆì¼ì¹˜ ê²€ì‚¬
        table_headings = re.findall(r'Table\s+\d+\.\d+\.\d+\.?\d*-[A-Z]', content)
        table_tags = re.findall(r'<table', content, re.IGNORECASE)
        if len(table_headings) > len(table_tags) + 2:
            self.warnings.append(('WARN', node_id,
                f'TABLE_MISMATCH: í…Œì´ë¸” í—¤ë”© {len(table_headings)}ê°œ, <table> {len(table_tags)}ê°œ'))

        # 7. ì§§ì€ content ê²€ì‚¬ (Subsectionì¸ë° ë„ˆë¬´ ì§§ìœ¼ë©´)
        parts = node_id.split('.')
        if len(parts) == 3 and len(content) < 100:  # Subsection level
            self.warnings.append(('WARN', node_id, f'SHORT_CONTENT: Subsectionì¸ë° {len(content)}ìë§Œ ìˆìŒ'))

        # 8. ê¹¨ì§„ HTML íƒœê·¸ ê²€ì‚¬
        open_tables = len(re.findall(r'<table', content, re.IGNORECASE))
        close_tables = len(re.findall(r'</table>', content, re.IGNORECASE))
        if open_tables != close_tables:
            self.errors.append(('ERROR', node_id,
                f'BROKEN_HTML: <table> {open_tables}ê°œ, </table> {close_tables}ê°œ'))

        # 9. PDF í˜ì´ì§€ ë¶„ë¦¬ ì§•í›„ ê²€ì‚¬
        if re.search(r'\d{4}\s+Building Code', content):
            self.warnings.append(('WARN', node_id, 'PDF_HEADER_LEAK: PDF í—¤ë”ê°€ contentì— í¬í•¨ë¨'))

        # 10. Raw HTML íƒœê·¸ ì”ë¥˜ ê²€ì‚¬ (<sup>, <sub> ë“±)
        raw_html_match = re.search(r'<(sup|sub|em|strong|b|i)>[^<]*</(sup|sub|em|strong|b|i)>', content, re.IGNORECASE)
        if raw_html_match:
            self.warnings.append(('WARN', node_id, f'RAW_HTML_TAG: <{raw_html_match.group(1)}> íƒœê·¸ ì”ë¥˜ - ìœ ë‹ˆì½”ë“œë¡œ ë³€í™˜ í•„ìš”'))

        # 11. Clause ì—°ì† í…ìŠ¤íŠ¸ ë¶„ë¦¬ ê²€ì‚¬
        # (a), (b), (c) ë’¤ì— ë°”ë¡œ ì†Œë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë³„ë„ ì¤„ì´ ìˆìœ¼ë©´ ê²½ê³ 
        # ì˜ˆ: "(c) something,\nwill result in..." â†’ ì—°ì† í…ìŠ¤íŠ¸ê°€ ì˜ëª» ë¶„ë¦¬ë¨
        separated_continuation = re.search(r'\([a-z]\)[^\n]*[,;]\s*\n[a-z]', content)
        if separated_continuation:
            snippet = separated_continuation.group()[:50].replace('\n', '\\n')
            self.warnings.append(('WARN', node_id, f'SEPARATED_CONTINUATION: clause ë’¤ ì—°ì† í…ìŠ¤íŠ¸ ë¶„ë¦¬ ì˜ì‹¬ - "{snippet}..."'))

        # 12. (See Note...) íŒ¨í„´ ë…ë¦½ ì¤„ ê²€ì‚¬
        # (See Note...)ê°€ ìƒˆ ì¤„ì—ì„œ ì‹œì‘í•˜ë©´ ì• clauseì™€ ë¶„ë¦¬ëœ ê²ƒì¼ ìˆ˜ ìˆìŒ
        see_note_newline = re.search(r'\n\s*\(See\s+Note\s+[A-Z]?-?\d', content, re.IGNORECASE)
        if see_note_newline:
            self.warnings.append(('WARN', node_id, 'SEPARATED_SEE_NOTE: (See Note...) íŒ¨í„´ì´ ë³„ë„ ì¤„ - ì• clauseì™€ ë¶„ë¦¬ ì˜ì‹¬'))

        # 13. ì¸ë¼ì¸ ë§ˆí¬ë‹¤ìš´ ì”ë¥˜ ê²€ì‚¬
        # ì˜ˆ: (**4)** ë³¼ë“œ clause ë²ˆí˜¸, *header line* ì´íƒ¤ë¦­ ìš©ì–´
        inline_bold = re.search(r'\(\*\*\d+\)\*\*', content)  # (**4)**
        if inline_bold:
            self.errors.append(('ERROR', node_id, f'INLINE_BOLD: ì¸ë¼ì¸ ë³¼ë“œ ë§ˆí¬ë‹¤ìš´ ì”ë¥˜ - "{inline_bold.group()}"'))

        inline_italic = re.search(r'(?<!\*)\*[a-zA-Z][^*\n]{1,30}\*(?!\*)', content)  # *italic term*
        if inline_italic:
            self.warnings.append(('WARN', node_id, f'INLINE_ITALIC: ì¸ë¼ì¸ ì´íƒ¤ë¦­ ë§ˆí¬ë‹¤ìš´ ì”ë¥˜ - "{inline_italic.group()}"'))

        # í†µê³„
        if '<table' in content.lower():
            self.stats['nodes_with_tables'] += 1
        self.stats['table_tags'] += len(table_tags)
        self.stats['table_headings'] += len(table_headings)

    def _report(self) -> bool:
        """ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""
        print(f"\nğŸ“Š Statistics:")
        print(f"   Total nodes: {self.stats['total_nodes']}")
        print(f"   Total content length: {self.stats['total_content_length']:,} chars")
        print(f"   Nodes with tables: {self.stats['nodes_with_tables']}")
        print(f"   Table headings found: {self.stats['table_headings']}")
        print(f"   <table> tags found: {self.stats['table_tags']}")

        if self.errors:
            print(f"\nâŒ Errors ({len(self.errors)}):")
            for level, node_id, msg in self.errors:
                print(f"   [{node_id}] {msg}")

        if self.warnings:
            print(f"\nâš ï¸  Warnings ({len(self.warnings)}):")
            for level, node_id, msg in self.warnings[:20]:  # ìµœëŒ€ 20ê°œë§Œ ì¶œë ¥
                print(f"   [{node_id}] {msg}")
            if len(self.warnings) > 20:
                print(f"   ... and {len(self.warnings) - 20} more warnings")

        if not self.errors and not self.warnings:
            print(f"\nâœ… All checks passed!")
            return True
        elif not self.errors:
            print(f"\nâœ… No errors, but {len(self.warnings)} warnings")
            return True
        else:
            print(f"\nâŒ {len(self.errors)} errors, {len(self.warnings)} warnings")
            return False


def main():
    if len(sys.argv) < 2:
        print("Usage:")
        print("  python validate_part.py <json_file>")
        print("  python validate_part.py <db_file> --db --part <part_number>")
        print("\nExamples:")
        print("  python validate_part.py codevault/public/data/part10.json")
        print("  python validate_part.py obc.db --db --part 11")
        sys.exit(1)

    validator = ParsingValidator()

    if '--db' in sys.argv:
        db_path = sys.argv[1]
        part_idx = sys.argv.index('--part') + 1
        part = sys.argv[part_idx]
        success = validator.validate_db(db_path, part)
    else:
        json_path = sys.argv[1]
        success = validator.validate_json(json_path)

    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
